{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis of dataset\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 5302, 86.72%\n",
      "Valid samples: 362, 5.92%\n",
      "Test samples: 450, 7.36%\n"
     ]
    }
   ],
   "source": [
    "# Sample amounts\n",
    "\n",
    "PATH_TRAIN = './datasets/train/images'\n",
    "PATH_VALID = './datasets/valid/images'\n",
    "PATH_TEST = './datasets/test/images'\n",
    "\n",
    "# Count of samples\n",
    "train_samples = len(os.listdir(PATH_TRAIN))\n",
    "valid_samples = len(os.listdir(PATH_VALID))\n",
    "test_samples = len(os.listdir(PATH_TEST))\n",
    "total_samples = train_samples + valid_samples + test_samples\n",
    "\n",
    "print(f'Train samples: {train_samples}, {train_samples/total_samples*100:.2f}%')\n",
    "print(f'Valid samples: {valid_samples}, {valid_samples/total_samples*100:.2f}%')\n",
    "print(f'Test samples: {test_samples}, {test_samples/total_samples*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of images files: 5302\n",
      "Initial number of labels files: 5302\n",
      "Total usable images and labels after filtering: 5302\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/train/labels/patch_0_0_combined_image_1726_png.rf.277d7e2dc3ea2b1d6eabaeb715333866.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m missing_annotations \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, label_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(LABEL_PATHS):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m label_file:\n\u001b[1;32m     24\u001b[0m         labels \u001b[38;5;241m=\u001b[39m label_file\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m labels:\n",
      "File \u001b[0;32m~/.conda/envs/miniproject_env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/train/labels/patch_0_0_combined_image_1726_png.rf.277d7e2dc3ea2b1d6eabaeb715333866.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load images\n",
    "\n",
    "PATH = \"datasets\"\n",
    "IM_PATH = PATH + \"/train/images\"\n",
    "LA_PATH = PATH + \"/train/labels\"\n",
    "image_files = sorted([f.split('.jpg')[0] for f in os.listdir(IM_PATH) if f.endswith('.jpg')])\n",
    "label_files = sorted([f.split('.txt')[0] for f in os.listdir(LA_PATH) if f.endswith('.txt')])\n",
    "\n",
    "matching_files = set(image_files).intersection(label_files)\n",
    "\n",
    "# Display number of images and labels\n",
    "print(\"Initial number of images files:\", len(image_files))\n",
    "print(\"Initial number of labels files:\", len(label_files))\n",
    "print(\"Total usable images and labels after filtering:\", len(matching_files))\n",
    "\n",
    "IMAGE_PATHS = [os.path.join(IM_PATH, f + '.jpg') for f in matching_files]\n",
    "LABEL_PATHS = [os.path.join(LA_PATH, f + '.txt') for f in matching_files]\n",
    "\n",
    "\n",
    "# Check for missing annotations\n",
    "missing_annotations = []\n",
    "for i, label_path in enumerate(LABEL_PATHS):\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        labels = label_file.read().splitlines()\n",
    "    if not labels:\n",
    "        missing_annotations.append(i)\n",
    "\n",
    "print(\"Missing annotations:\", missing_annotations)\n",
    "\n",
    "# Display number of images and labels\n",
    "total_labels = sum(len(open(label_path, 'r').read().splitlines()) for label_path in LABEL_PATHS)\n",
    "print(\"Number of images:\", len(IMAGE_PATHS))\n",
    "print(\"Number of labels:\", total_labels)\n",
    "\n",
    "# Display dimensions of the images\n",
    "print(\"Image dimensions:\", cv2.imread(IMAGE_PATHS[0]).shape)\n",
    "\n",
    "# Function to overlay labels on an image\n",
    "def overlay_labels(image_path, label_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Load the corresponding label file\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        labels = label_file.read().splitlines()\n",
    "\n",
    "    # Overlay labels on the image\n",
    "    for l in labels:\n",
    "        # Parse label: format is \"class x_center y_center width height\"\n",
    "        label_data = l.split()\n",
    "        cls, x_center, y_center, width, height = map(float, label_data)\n",
    "        \n",
    "        # Convert YOLO format (normalized) to pixel values\n",
    "        img_h, img_w = image.shape[:2]\n",
    "        x_center = int(x_center * img_w)\n",
    "        y_center = int(y_center * img_h)\n",
    "        width = int(width * img_w)\n",
    "        height = int(height * img_h)\n",
    "\n",
    "        # Calculate top-left and bottom-right corners\n",
    "        x1 = x_center - width // 2\n",
    "        y1 = y_center - height // 2\n",
    "        x2 = x_center + width // 2\n",
    "        y2 = y_center + height // 2\n",
    "\n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "        # Optionally, display the class label\n",
    "        cv2.putText(image, f\"Pole\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Display the first 5 images with labels\n",
    "num_images_to_display = 10\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    # Load the original image\n",
    "    original_image = cv2.imread(IMAGE_PATHS[i])\n",
    "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay labels on the image\n",
    "    labeled_image = overlay_labels(IMAGE_PATHS[i], LABEL_PATHS[i])\n",
    "    \n",
    "    # Add subplot for the original image (left column)\n",
    "    plt.subplot(num_images_to_display, 2, 2 * i + 1)\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis('off')  # Hide axes for better visualization\n",
    "    plt.title(f\"Original {i + 1}\")\n",
    "\n",
    "    # Add subplot for the labeled image (right column)\n",
    "    plt.subplot(num_images_to_display, 2, 2 * i + 2)\n",
    "    plt.imshow(labeled_image)\n",
    "    plt.axis('off')  # Hide axes for better visualization\n",
    "    plt.title(f\"Labeled {i + 1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see that the poles most frequently are places at the bottom of the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total label area: 1487029.5673879024\n",
      "Total image area: 379322368\n",
      "Ratio of label area to image area: 0.003920226416460372\n",
      "Percentage of image area covered by labels: 0.39%\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to calculate total label area and total image area\n",
    "total_label_area = 0\n",
    "total_image_area = 0\n",
    "\n",
    "# Loop through all images and labels\n",
    "for image_path, label_path in zip(IMAGE_PATHS, LABEL_PATHS):\n",
    "    # Load the image to get dimensions\n",
    "    image = cv2.imread(image_path)\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    image_area = img_h * img_w\n",
    "    total_image_area += image_area  # Add the area of the current image to the total\n",
    "\n",
    "    # Load the corresponding label file\n",
    "    with open(label_path, 'r') as label_file:\n",
    "        labels = label_file.read().splitlines()\n",
    "\n",
    "    # Calculate the area of each bounding box\n",
    "    for l in labels:\n",
    "        # Parse label: format is \"class x_center y_center width height\"\n",
    "        _, x_center, y_center, width, height = map(float, l.split())\n",
    "        \n",
    "        # Convert normalized width and height to pixel values\n",
    "        width_px = width * img_w\n",
    "        height_px = height * img_h\n",
    "\n",
    "        # Calculate the area of the bounding box\n",
    "        bbox_area = width_px * height_px\n",
    "        total_label_area += bbox_area  # Add the bounding box area to the total\n",
    "\n",
    "# Calculate the ratio of label area to image area\n",
    "label_to_image_ratio = total_label_area / total_image_area\n",
    "\n",
    "# Display the results\n",
    "print(\"Total label area:\", total_label_area)\n",
    "print(\"Total image area:\", total_image_area)\n",
    "print(\"Ratio of label area to image area:\", label_to_image_ratio)\n",
    "print(f\"Percentage of image area covered by labels: {label_to_image_ratio * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bounding box area as ratio of image: 0.001897\n",
      "Average poles per image: 2.07\n"
     ]
    }
   ],
   "source": [
    "bbox_areas = []\n",
    "\n",
    "# Loop through each .txt file in the directory\n",
    "for file in LABEL_PATHS:\n",
    "    with open(file, 'r') as f:\n",
    "        annotations = f.readlines()  # Read all lines in the file\n",
    "        for annotation in annotations:\n",
    "            # Parse each line in YOLO format: class_id x_center y_center width height\n",
    "            _, x_center, y_center, width, height = map(float, annotation.split())\n",
    "            \n",
    "            # Calculate the bounding box area (YOLO dimensions are normalized)\n",
    "            area = width * height  # Area in normalized units (as fraction of image area)\n",
    "            bbox_areas.append(area)\n",
    "\n",
    "# Calculate and print the average bounding box area\n",
    "print(f\"Average bounding box area as ratio of image: {sum(bbox_areas)/len(bbox_areas):.6f}\")\n",
    "\n",
    "\n",
    "counts = []\n",
    "\n",
    "# Loop through each .txt file in the directory\n",
    "for file in LABEL_PATHS:\n",
    "    with open(file, 'r') as f:\n",
    "        annotations = f.readlines()  # Read all lines in the file\n",
    "        counts.append(len(annotations))  # Count the number of lines (objects)\n",
    "\n",
    "# Calculate and print the average poles per image\n",
    "print(f\"Average poles per image: {sum(counts)/len(counts):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vi_project",
   "language": "python",
   "name": "vi_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
